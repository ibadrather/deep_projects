{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will build a Neural Network for Bank Note Prediction now.\n",
    "\n",
    "This is not a very challenging deep learning problem. But just for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset into test and train dataset\n",
    "dataset = pd.read_csv(\"BankNote_Authentication.csv\")\n",
    "\n",
    "# Features\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "# Targets\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number train samples 1234\n",
      "Number test samples 138\n"
     ]
    }
   ],
   "source": [
    "class BankDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.targets = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.features[idx]), torch.tensor(self.targets[idx], dtype=torch.float32)   #.unsqueeze(0)   #torch.Tensor(self.targets[idx]).long()\n",
    "        #return self.features[idx], torch.tensor(self.targets[idx]).to(dtype=torch.long)\n",
    "\n",
    "train_dataset = BankDataset(X_train, y_train)\n",
    "test_dataset = BankDataset(X_test, y_test)\n",
    "\n",
    "print(\"Number train samples\", len(train_dataset))\n",
    "print(\"Number test samples\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders for training and testing\n",
    "trainloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "testloader = DataLoader(test_dataset, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "a = iter(trainloader)\n",
    "\n",
    "feat, targ = next(a)\n",
    "\n",
    "print(feat.shape)\n",
    "print(targ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers=[24, 16, 8, 4], drop_p=0.5):\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ptl module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankNoteClassifier(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-5):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Criterion\n",
    "        self.criterion = nn.MSELoss()   #nn.BCELoss()   #nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        # Accuracy\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    #F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        oscillation, label = batch\n",
    "        \n",
    "        logits = self.forward(oscillation)\n",
    "        loss = self.criterion(logits, label)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        oscillation, label = batch\n",
    "\n",
    "        logits = self.forward(oscillation)\n",
    "        loss = self.criterion(logits, label)\n",
    "        preds = F.log_softmax(logits, dim=1).argmax(dim=1)\n",
    "        self.val_accuracy.update(preds, label)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        oscillation, label = batch\n",
    "\n",
    "        logits = self.forward(oscillation)\n",
    "        loss = self.criterion(logits, label)\n",
    "        preds = F.log_softmax(logits, dim=1).argmax(dim=1)\n",
    "        self.test_accuracy.update(preds, label)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.model.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BankModel(input_size=4, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BankModel(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=24, bias=True)\n",
      "    (1): Linear(in_features=24, out_features=16, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (3): Linear(in_features=8, out_features=4, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Defining Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"training_output\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k = 2,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\"\n",
    ")\n",
    "\n",
    "# Log to Tensor Board\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name = \"bank-predict\")\n",
    "\n",
    "# Stop trainining if model is not improving\n",
    "early_stopping_callback = EarlyStopping(monitor = \"train_loss\", patience = 50)\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = TQDMProgressBar(refresh_rate=1)\n",
    "\n",
    "# Model\n",
    "model = BankNoteClassifier(net, learning_rate=1e-5)\n",
    "\n",
    "# Defining a Pytorch Lightning Trainer\n",
    "N_EPOCHS = 50\n",
    "trainer = pl.Trainer(\n",
    "    logger = logger,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=2,\n",
    "    callbacks = [early_stopping_callback, early_stopping_callback, progress_bar],\n",
    "    max_epochs = N_EPOCHS,\n",
    "    accelerator='gpu',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibad/venvs/deeply/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:117: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params\n",
      "--------------------------------------------\n",
      "0 | model         | BankModel | 697   \n",
      "1 | criterion     | MSELoss   | 0     \n",
      "2 | val_accuracy  | Accuracy  | 0     \n",
      "3 | test_accuracy | Accuracy  | 0     \n",
      "--------------------------------------------\n",
      "697       Trainable params\n",
      "0         Non-trainable params\n",
      "697       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "/home/ibad/venvs/deeply/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025725841522216797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1562a36681a94025b59f8c23afe4d7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibad/venvs/deeply/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ibad/venvs/deeply/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ibad/venvs/deeply/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer.fit(model, train_dataloaders=trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deeply')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ba283c99aab3f9826c9057a6b77e5ed1375b1012fccd26237ed2bb4d681a306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
